{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fibit Time Series independent project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "\n",
    "1. This notebook containing your analysis, summary, and conclusions\n",
    "\n",
    "\n",
    "2. A tidied data set. The source data is a little messy the data was edited in Google Sheets then downloaded into a csv for upload here.\n",
    "\n",
    "\n",
    "3. A summarization of the data.\n",
    "    - What do you make of the data?\n",
    "    - What can you say say about the individual who was wearing this fitness tracker?   \n",
    "  \n",
    "  \n",
    "4. Predictions for the missing two weeks worth of data in a separate csv file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import Holt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting defaults\n",
    "plt.rc('figure', figsize=(13, 7))\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rc('font', size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fitbit_all_activity.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-80e203b3b176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fitbit_all_activity.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fitbit_all_activity.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('fitbit_all_activity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1.date = pd.to_datetime(df1.date)\n",
    "df1 = df1.set_index('date').sort_index()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()\n",
    "# need to convert all columns to numbers, fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view histograms - ok before split b/c all independent\n",
    "df1.hist(figsize=(9, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split and validate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_size = int(len(df1) * .5)\n",
    "validate_size = int(len(df1) * .3)\n",
    "test_size = int(len(df1) - train_size - validate_size)\n",
    "validate_end_index = train_size + validate_size\n",
    "\n",
    "# split into train, validation, test\n",
    "train = df1[: train_size]\n",
    "validate = df1[train_size : validate_end_index]\n",
    "test = df1[validate_end_index : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the length of each df equate to the length of the original df?\n",
    "print(len(train) + len(validate) + len(test) == len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the first row of original df equate to the first row of train?\n",
    "print(df1.head(1) == train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the last row of train the day before the first row of validate? And the same for validate to test?\n",
    "pd.concat([train.tail(1), validate.head(1)])\n",
    "pd.concat([validate.tail(1), test.head(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the last row of test the same as the last row of our original dataframe?\n",
    "pd.concat([test.tail(1), df1.tail(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(train[col])\n",
    "    plt.plot(validate[col])\n",
    "    plt.plot(test[col])\n",
    "    plt.ylabel(col)\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = train.cal_burned\n",
    "cb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = train.steps\n",
    "steps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month'] = train.index.month\n",
    "train.groupby('month').cal_burned.mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('month').steps.mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['weekday'] = train.index.day_name()\n",
    "order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "sns.boxplot(data=train, y='cal_burned', x='weekday', order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=train, y='steps', x='weekday', order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=train, y='min_sed', x='weekday', order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=train, y='min_light', x='weekday', order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=train, y='min_fair', x='weekday', order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=train, y='min_very', x='weekday', order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.resample('3D').mean().plot(title='3 Day average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.resample('W').mean().plot(title='week average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = train.steps\n",
    "steps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps.resample('3D').mean().plot(title='3 Day average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps.resample('W').mean().plot(title='week average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(cb, cb.shift(-1))\n",
    "plt.xlabel('$cb$')\n",
    "plt.ylabel('$cb_{t + 1}$')\n",
    "plt.title('Lag plot with lag=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train['cb(t + 1)']\n",
    "# del train['month']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['min_sed', 'min_light', 'min_fair', 'min_very']].resample('M').sum().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly = train.resample('W').mean()\n",
    "weekly['the_next_week'] = weekly.cal_burned.shift(-1)\n",
    "weekly = weekly.rename(columns={'cal_burned': 'this_week'})\n",
    "weekly.plot.scatter(x='this_week', y='the_next_week')\n",
    "weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**     \n",
    "- there is not a cyclical/seasonal pattern to this data\n",
    "- slight linear upward trend\n",
    "- dataset is too small for cycle or seasonal trend to show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to help with modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function to compute rmse\n",
    "def evaluate(target_var):\n",
    "    rmse = round(sqrt(mean_squared_error(validate[target_var], yhat_df[target_var])), 0)\n",
    "    return rmse\n",
    "\n",
    "# plot and evaluate \n",
    "def plot_and_eval(target_var):\n",
    "    plt.figure(figsize = (12,4))\n",
    "    plt.plot(train[target_var], label = 'Train', linewidth = 1)\n",
    "    plt.plot(validate[target_var], label = 'Validate', linewidth = 1)\n",
    "    plt.plot(yhat_df[target_var])\n",
    "    plt.title(target_var)\n",
    "    rmse = evaluate(target_var)\n",
    "    print(target_var, '-- RMSE: {:.0f}'.format(rmse))\n",
    "    plt.show()\n",
    "    \n",
    "# Create the empty dataframe\n",
    "eval_df = pd.DataFrame(columns=['model_type', 'target_var', 'rmse'])\n",
    "\n",
    "# function to store rmse for comparison purposes\n",
    "def append_eval_df(model_type, target_var):\n",
    "    rmse = evaluate(target_var)\n",
    "    d = {'model_type': [model_type], 'target_var': [target_var], 'rmse': [rmse]}\n",
    "    d = pd.DataFrame(d)\n",
    "    return eval_df.append(d, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last Observed Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns not needed for modeling from train\n",
    "del train['distance']\n",
    "del train['floors']\n",
    "del train['activity_cal']\n",
    "del train['month']\n",
    "del train['weekday']\n",
    "\n",
    "# remove columns not needed for modeling from validate\n",
    "del validate['distance']\n",
    "del validate['floors']\n",
    "del validate['activity_cal']\n",
    "\n",
    "# remove columns not needed for modeling from test\n",
    "del test['distance']\n",
    "del test['floors']\n",
    "del test['activity_cal']\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last observed value and set that as prediction for all in validate\n",
    "cal_burned = train['cal_burned'][-1:][0]\n",
    "steps = train['steps'][-1:][0]\n",
    "min_sed = train['min_sed'][-1:][0]\n",
    "min_light = train['min_light'][-1:][0]\n",
    "min_fair = train['min_fair'][-1:][0]\n",
    "min_very = train['min_very'][-1:][0]\n",
    "\n",
    "yhat_df = pd.DataFrame({'cal_burned': [cal_burned], 'steps': [steps], 'min_sed': [min_sed], \n",
    "                        'min_light': [min_light], 'min_fair': [min_fair], 'min_very': [min_very]}, \n",
    "                       index = validate.index)\n",
    "\n",
    "yhat_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predicted values\n",
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = 'last_observed_value', \n",
    "                             target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average and use that to make predictions for all in validate\n",
    "cal_burned = train['cal_burned'].mean()\n",
    "steps = train['steps'].mean()\n",
    "min_sed = train['min_sed'].mean()\n",
    "min_light = train['min_light'].mean()\n",
    "min_fair = train['min_fair'].mean()\n",
    "min_very = train['min_very'].mean()\n",
    "\n",
    "# create function for later repitition\n",
    "def make_predictions():\n",
    "    yhat_df = pd.DataFrame({'cal_burned': [cal_burned], 'steps': [steps], 'min_sed': [min_sed], \n",
    "                        'min_light': [min_light], 'min_fair': [min_fair], 'min_very': [min_very]}, \n",
    "                           index = validate.index)\n",
    "    return yhat_df\n",
    "\n",
    "yhat_df = make_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type='simple_average', \n",
    "                             target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30 day rolling average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a 30 day rolling average, \n",
    "# use the most recent/last 30 day period value to predict forward. \n",
    "period = 30\n",
    "\n",
    "cal_burned = round(train['cal_burned'].rolling(period).mean().iloc[-1], 1)\n",
    "steps = round(train['steps'].rolling(period).mean().iloc[-1], 1)\n",
    "min_sed = round(train['min_sed'].rolling(period).mean().iloc[-1], 1)\n",
    "min_light = round(train['min_light'].rolling(period).mean().iloc[-1], 1)\n",
    "min_fair = round(train['min_fair'].rolling(period).mean().iloc[-1], 1)\n",
    "min_very = round(train['min_very'].rolling(period).mean().iloc[-1], 1)\n",
    "\n",
    "yhat_df = make_predictions()\n",
    "yhat_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type='30d moving average', \n",
    "                             target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### additional rolling average periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [1, 4, 12, 26, 52, 104]\n",
    "\n",
    "for p in periods:\n",
    "    cal_burned = round(train['cal_burned'].rolling(period).mean().iloc[-1], 1)\n",
    "    steps = round(train['steps'].rolling(period).mean().iloc[-1], 1)\n",
    "    min_sed = round(train['min_sed'].rolling(period).mean().iloc[-1], 1)\n",
    "    min_light = round(train['min_light'].rolling(period).mean().iloc[-1], 1)\n",
    "    min_fair = round(train['min_fair'].rolling(period).mean().iloc[-1], 1)\n",
    "    min_very = round(train['min_very'].rolling(period).mean().iloc[-1], 1)\n",
    "    yhat_df = make_predictions()\n",
    "    model_type = str(p) + 'd moving average'\n",
    "    for col in train.columns:\n",
    "        eval_df = append_eval_df(model_type = model_type, \n",
    "                                 target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the min rmse for each variable\n",
    "\n",
    "# min_rmse_cb = eval_df.groupby('target_var')['rmse'].min()[0]\n",
    "# min_rmse_min_fair = eval_df.groupby('target_var')['rmse'].min()[1]\n",
    "# min_rmse_min_light = eval_df.groupby('target_var')['rmse'].min()[2]\n",
    "# min_rmse_min_sed = eval_df.groupby('target_var')['rmse'].min()[3]\n",
    "# min_rmse_min_very = eval_df.groupby('target_var')['rmse'].min()[-2]\n",
    "# min_rmse_steps = eval_df.groupby('target_var')['rmse'].min()[-1]\n",
    "\n",
    "# # filter only the rows that match those rmse to find out \n",
    "# # which models are best thus far\n",
    "# eval_df[((eval_df.rmse == min_rmse_cb) | \n",
    "#          (eval_df.rmse == min_rmse_min_fair) | (eval_df.rmse == min_rmse_min_light) | \n",
    "#          (eval_df.rmse == min_rmse_min_sed) | (eval_df.rmse == min_rmse_min_very) | \n",
    "#          (eval_df.rmse == min_rmse_steps)\n",
    "#         )]\n",
    "\n",
    "eval_df.groupby(['target_var', 'model_type'])[['rmse']].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best so far = any of rolling average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holts Linear Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    print(col,'\\n')\n",
    "    _ = sm.tsa.seasonal_decompose(train[col].resample('D').mean()).plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    model = Holt(train[col], exponential = False, damped=True)\n",
    "    model = model.fit(smoothing_level = .1, \n",
    "                      smoothing_slope = .1, \n",
    "                      optimized = True)\n",
    "    yhat_items = model.predict(start = validate.index[0], \n",
    "                               end = validate.index[-1])\n",
    "    yhat_df[col] = round(yhat_items, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = 'Holts', \n",
    "                             target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on previous cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not going to use this model because data does not have seasonal/cycle in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model evaluation and test\n",
    "\n",
    "- best performing models are the rolling average, no difference between # of days\n",
    "- will use 7 days and try on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.groupby(['target_var', 'model_type'])[['rmse']].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = pd.DataFrame(eval_df[eval_df.model_type == '4d moving average'])\n",
    "test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat train with validate to create predictions for test\n",
    "train_val = pd.concat(train, validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a 7 day rolling average, \n",
    " \n",
    "period = 7\n",
    "\n",
    "cal_burned = round(train['cal_burned'].rolling(period).mean().iloc[-1], 1)\n",
    "steps = round(train['steps'].rolling(period).mean().iloc[-1], 1)\n",
    "min_sed = round(train['min_sed'].rolling(period).mean().iloc[-1], 1)\n",
    "min_light = round(train['min_light'].rolling(period).mean().iloc[-1], 1)\n",
    "min_fair = round(train['min_fair'].rolling(period).mean().iloc[-1], 1)\n",
    "min_very = round(train['min_very'].rolling(period).mean().iloc[-1], 1)\n",
    "\n",
    "yhat_df = pd.DataFrame({'cal_burned': [cal_burned], 'steps': [steps], 'min_sed': [min_sed], \n",
    "                        'min_light': [min_light], 'min_fair': [min_fair], 'min_very': [min_very]}, \n",
    "                           index = test.index)\n",
    "yhat_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_plot(target_var):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(train[target_var], label='train')\n",
    "    plt.plot(validate[target_var], label = 'validate')\n",
    "    plt.plot(test[target_var], label = 'test')\n",
    "    plt.plot(yhat_df[target_var], alpha=.5)\n",
    "    plt.title(target_var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    final_plot(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cal_burned = sqrt(mean_squared_error(test['cal_burned'], yhat_df['cal_burned']))\n",
    "rmse_steps = sqrt(mean_squared_error(test['steps'], yhat_df['steps']))\n",
    "rmse_min_sed = sqrt(mean_squared_error(test['min_sed'], yhat_df['min_sed']))\n",
    "rmse_min_light = sqrt(mean_squared_error(test['min_light'], yhat_df['min_light']))\n",
    "rmse_min_fair = sqrt(mean_squared_error(test['min_fair'], yhat_df['min_fair']))\n",
    "rmse_min_very = sqrt(mean_squared_error(test['min_very'], yhat_df['min_very']))\n",
    "\n",
    "print('rmse_cal_burned=', rmse_cal_burned)\n",
    "print('rmse_steps=', rmse_steps)\n",
    "print('rmse_min_sed=', rmse_min_sed)\n",
    "print('rmse_min_light=', rmse_min_light)\n",
    "print('rmse_min_fair=', rmse_min_fair)\n",
    "print('rmse_min_very=', rmse_min_very)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_evaluate(target_var):\n",
    "    rmse = round(sqrt(mean_squared_error(test[target_var], yhat_df[target_var])), 0)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to store rmse for comparison purposes\n",
    "def final_append_eval_df(model_type, target_var):\n",
    "    rmse = final_evaluate(target_var)\n",
    "    d = {'model_type': [model_type], 'target_var': [target_var], 'rmse': [rmse]}\n",
    "    d = pd.DataFrame(d)\n",
    "    return test_eval.append(d, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    test_eval = final_append_eval_df(model_type = '7d rolling everage', \n",
    "                             target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to predict 2018\n",
    "\n",
    "# yhat_df = test + train.diff(365).mean()\n",
    "# yhat_df.index = test.index + pd.Timedelta('1Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a 7 day rolling average using test, \n",
    "# predict out 2 weeks based on this average for next 2 weeks predictions\n",
    "period = 7\n",
    "\n",
    "cal_burned = round(test['cal_burned'].rolling(period).mean().iloc[-1], 1)\n",
    "steps = round(test['steps'].rolling(period).mean().iloc[-1], 1)\n",
    "min_sed = round(test['min_sed'].rolling(period).mean().iloc[-1], 1)\n",
    "min_light = round(test['min_light'].rolling(period).mean().iloc[-1], 1)\n",
    "min_fair = round(test['min_fair'].rolling(period).mean().iloc[-1], 1)\n",
    "min_very = round(test['min_very'].rolling(period).mean().iloc[-1], 1)\n",
    "\n",
    "yhat_df = pd.DataFrame({'cal_burned': [cal_burned], 'steps': [steps], 'min_sed': [min_sed], \n",
    "                        'min_light': [min_light], 'min_fair': [min_fair], 'min_very': [min_very]}, \n",
    "                           index = test.index + pd.Timedelta('2W'))\n",
    "yhat_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual with future 2 week forecast\n",
    "for col in train.columns:\n",
    "    final_plot(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 week prediction csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv of 2 week predictions\n",
    "yhat_df.to_csv('predictions_2weeks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
